{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "983ec67b",
   "metadata": {},
   "source": [
    "# Title : Object detection using Transfer Learning of CNN architectures\n",
    "Aim: Object detection using Transfer Learning of CNN architectures\n",
    "    \n",
    "a. Load in a pre-trained CNN model trained on a large dataset\n",
    "\n",
    "b. Freeze parameters (weights) in model’s lower convolutional layers\n",
    "\n",
    "c. Add custom classifier with several layers of trainable parameters to model\n",
    "\n",
    "d. Train classifier layers on training data available for task\n",
    "\n",
    "e. Fine-tune hyper parameters and unfreeze more layers as needed\n",
    "\n",
    "dataset\n",
    "https://drive.google.com/file/d/1lKQYLe3WrhUtV0V0PLsp47dJhA-tWACj/view?usp=drive_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31c2e651-8075-41a1-b996-30bca14f1627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten  #Dense layer is a fully connected layer (feedforward layer) #Flatten layer is used to convert multi-dimensional data, such as images, into a one-dimensional vector\n",
    "from tensorflow.keras.optimizers import Adam  # Adam optimizer is a popular optimization algorithm used in training deep learning models,\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator #used for image data augmentation rotation, resizing, shearing, flipping, zooming\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203d03af-e7eb-406f-b9dc-9dad72072a3f",
   "metadata": {},
   "source": [
    "#### Pre processing img data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bae4a153-6f00-4265-add9-35904409dd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40079 images belonging to 10 classes.\n",
      "Found 9921 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dir = \"Datasets/cifar-10-img/train\"\n",
    "test_dir = \"Datasets/cifar-10-img/test\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(  #Keras utility for data augmentation\n",
    "    rescale=1.0 / 255,  #scales the pixel values of the images in your dataset to be in the range [0, 1].\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    ")\n",
    "\n",
    "# here batch_size is the number of images in each batch\n",
    "train_batch_size = 5000\n",
    "train_generator = train_datagen.flow_from_directory( #ImageDataGenerator that generates batches of augmented data from images stored in a directory\n",
    "    train_dir,\n",
    "    target_size=(32, 32),#images will be resized to a 32x32 pixel size\n",
    "    batch_size=train_batch_size,\n",
    "    class_mode='categorical' # specified 'categorical', which is appropriate for multi-class classification tasks\n",
    ")\n",
    "\n",
    "\n",
    "test_batch_size = 1000\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(32, 32),\n",
    "    batch_size=test_batch_size,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4609c200-c5fc-4067-b3b3-bd8b7226e27d",
   "metadata": {},
   "source": [
    "#### Selecting only first batch with 5000 images as train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4369f09-67f5-4f91-a6f2-971ed179dea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train =  train_generator[0]\n",
    "x_test, y_test = test_generator[0]\n",
    "\n",
    "print(len(x_train))\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db56097-894f-44a2-8b54-8241acd0dea9",
   "metadata": {},
   "source": [
    "#### a. Load in a pre-trained CNN model trained on a large dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e80ede0-af89-4fd0-b431-191d5f6401d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VGG16 without top layers  , VGG16 consists of 16 layers, which include 13 convolutional layers and 3 fully connected layers\n",
    "weights_path = \"imagenet\"  #variable contains the path to a file that holds the pre-trained weights for the VGG16 model\n",
    "base_model = VGG16(weights=weights_path, include_top=False, input_shape=(32, 32, 3)) #variable will store the VGG16 model with the specified configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfc0b6a-99ae-4197-aae2-288d54241ce4",
   "metadata": {},
   "source": [
    "#### b. Freeze parameters (weights) in model’s lower convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b64173b6-f973-416d-95a5-bfb158f9aa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "   layer.trainable = False  #Setting the layers to non-trainable means that the weights and parameters of these layers will not be updated during the training of your specific task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324ff8f4-4cb4-451e-a72b-3f35ee41f600",
   "metadata": {},
   "source": [
    "#### c. Add custom classifier with several layers of trainable parameters to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e44e9909-36b2-48cb-8470-1e6648a229a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Flatten()(base_model.output)  #This line adds a Flatten layer on top of the output of the base_model\n",
    "x = Dense(256, activation='relu')(x) #This line adds a fully connected layer with 256 neurons and ReLU\n",
    "x = tf.keras.layers.Dropout(0.3)(x) #It creates a dropout layer with a dropout rate of 0.3.\n",
    "x = Dense(256, activation='relu')(x) #This creates a dense layer with 256 neurons and applies ReLU \n",
    "x = tf.keras.layers.Dropout(0.3)(x)#It creates a dropout layer with a dropout rate of 0.3.\n",
    "predictions = Dense(10, activation='softmax')(x)  #fully connected layer with 10 neurons (assuming this is for a classification task with 10 classes) and a softmax activation function is added. This layer produces the output of the model, which represents the predicted class probabilities for the input data.\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=base_model.input, outputs=predictions) #This creates a new Keras model where base_model.input specifies the input of the model (the input of the VGG16 base model), and predictions represents the output of the model\n",
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy']) #You are specifying the Adam optimizer for training,s specifies the evaluation metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0aac27-8b92-4f9d-a43a-af5633d440b8",
   "metadata": {},
   "source": [
    "#### d. Train classifier layers on training data available for task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ce936f9-8497-4be8-877b-63d8f7c27885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "79/79 [==============================] - 28s 334ms/step - loss: 1.9523 - accuracy: 0.2888 - val_loss: 1.5625 - val_accuracy: 0.4390\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 27s 342ms/step - loss: 1.5994 - accuracy: 0.4292 - val_loss: 1.4154 - val_accuracy: 0.4870\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 28s 355ms/step - loss: 1.4485 - accuracy: 0.4902 - val_loss: 1.3756 - val_accuracy: 0.4960\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 28s 349ms/step - loss: 1.3747 - accuracy: 0.5142 - val_loss: 1.3308 - val_accuracy: 0.5080\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 27s 349ms/step - loss: 1.2975 - accuracy: 0.5412 - val_loss: 1.3251 - val_accuracy: 0.5270\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 27s 348ms/step - loss: 1.2485 - accuracy: 0.5584 - val_loss: 1.3045 - val_accuracy: 0.5320\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 28s 353ms/step - loss: 1.1807 - accuracy: 0.5704 - val_loss: 1.2889 - val_accuracy: 0.5420\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 27s 345ms/step - loss: 1.1364 - accuracy: 0.6012 - val_loss: 1.2836 - val_accuracy: 0.5260\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 28s 359ms/step - loss: 1.0984 - accuracy: 0.6140 - val_loss: 1.3297 - val_accuracy: 0.5260\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 30s 380ms/step - loss: 1.0532 - accuracy: 0.6270 - val_loss: 1.3026 - val_accuracy: 0.5450\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x26cb057d9a0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=10, validation_data=(x_test, y_test))  #each training epoch, the model's performance will be evaluated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521fc40f-4c47-462f-8965-9026bdb98edb",
   "metadata": {},
   "source": [
    "#### e. Fine-tune hyper parameters and unfreeze more layers as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1d6efc6-3209-4586-8947-385a0120f861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "79/79 [==============================] - 94s 1s/step - loss: 1.8541 - accuracy: 0.3178 - val_loss: 1.6245 - val_accuracy: 0.4170\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 93s 1s/step - loss: 1.3206 - accuracy: 0.5326 - val_loss: 1.4945 - val_accuracy: 0.5330\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 97s 1s/step - loss: 1.0634 - accuracy: 0.6348 - val_loss: 1.2190 - val_accuracy: 0.5830\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 98s 1s/step - loss: 0.9265 - accuracy: 0.6892 - val_loss: 1.0803 - val_accuracy: 0.6190\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 96s 1s/step - loss: 0.7634 - accuracy: 0.7442 - val_loss: 1.1436 - val_accuracy: 0.6280\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 102s 1s/step - loss: 0.6933 - accuracy: 0.7688 - val_loss: 1.1338 - val_accuracy: 0.6380\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 99s 1s/step - loss: 0.5512 - accuracy: 0.8156 - val_loss: 1.4275 - val_accuracy: 0.6030\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 101s 1s/step - loss: 0.4941 - accuracy: 0.8342 - val_loss: 1.4019 - val_accuracy: 0.6060\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 102s 1s/step - loss: 0.4569 - accuracy: 0.8498 - val_loss: 1.3114 - val_accuracy: 0.6250\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 106s 1s/step - loss: 0.3564 - accuracy: 0.8802 - val_loss: 1.3003 - val_accuracy: 0.6510\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x26cc53bc0a0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = VGG16(weights=weights_path, include_top=False, input_shape=(32, 32, 3))\n",
    "# freeze all layers first\n",
    "for layer in base_model.layers:\n",
    "   layer.trainable = False\n",
    "\n",
    "# unfreeze last 4 layers of base model\n",
    "for layer in base_model.layers[len(base_model.layers) - 4:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "# fine-tuning hyper parameters\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.3)(x)\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# training fine tuned model\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=10, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc035871-ca9a-4c0e-9204-d999e14c53c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 5s 137ms/step\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "predicted_value = model.predict(x_test)  # This line uses your trained model to make predictions on the testing data (x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3637d2e8-05ea-4e4d-a38b-b2c1ca6c76be",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(test_generator.class_indices.keys())  #This code extracts the class names (labels) by obtaining the keys from the dictionary, and then it converts those keys into a list. This list will contain the class labels you can use for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d4825f5-8e54-47a9-ab3b-57e55c9d11f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preditcted:  deer\n",
      "Actual:  deer\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 900#You're selecting a specific index (n) from your testing data\n",
    "plt.imshow(x_test[n]) # line uses Matplotlib to display the image at index n\n",
    "print(\"Preditcted: \",labels[np.argmax(predicted_value[n])])\n",
    "print(\"Actual: \", labels[np.argmax(y_test[n])])  #is used to find the index with the highest predicted value, which corresponds to the predicted class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb20eb20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
